{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2606f2dd",
   "metadata": {},
   "source": [
    "### ***THỰC HÀNH TRANSFER LEARNING TRÊN TẬP pizza_steak_sushi***\n",
    "Các file cần thiết đã được lưu (xem docs).  \n",
    "Các module quan trọng trong file sẽ được viết thành file và chạy ở train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc619611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os \n",
    "data_path = Path('pizza_steak_sushi/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94395652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\envs\\DL_ENV\\lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dataloader import dataprocess\n",
    "datamodule = dataprocess.DataModule(data_dir=data_path, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e4f960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x272ae765840>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x272fed70670>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.setup()\n",
    "train_loader, test_loader = datamodule.train_dataloader(), datamodule.test_dataloader()\n",
    "class_names = datamodule.get_class_names()\n",
    "train_loader,test_loader,class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94466236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[256]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BICUBIC\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # DEFAULT chọn ra trọng số tốt nhất\n",
    "auto_transform = weights.transforms()\n",
    "auto_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19731bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from backbones import efficient_b0\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31d75885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "datamodule = dataprocess.DataModule(data_dir = data_path, batch_size=16)\n",
    "model = torchvision.models.efficientnet_b0()\n",
    "transfer = efficient_b0.Transfered_Model(unfreeze_lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b58f452b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=======================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape               Output Shape              Trainable\n",
       "=======================================================================================================================================\n",
       "Transfered_Model (Transfered_Model)                          [16, 3, 224, 224]         [16, 3]                   Partial\n",
       "├─Sequential (block_1)                                       [16, 3, 224, 224]         [16, 1280, 7, 7]          Partial\n",
       "│    └─Conv2dNormActivation (0)                              [16, 3, 224, 224]         [16, 32, 112, 112]        False\n",
       "│    │    └─Conv2d (0)                                       [16, 3, 224, 224]         [16, 32, 112, 112]        False\n",
       "│    │    └─BatchNorm2d (1)                                  [16, 32, 112, 112]        [16, 32, 112, 112]        False\n",
       "│    │    └─SiLU (2)                                         [16, 32, 112, 112]        [16, 32, 112, 112]        --\n",
       "│    └─Sequential (1)                                        [16, 32, 112, 112]        [16, 16, 112, 112]        False\n",
       "│    │    └─MBConv (0)                                       [16, 32, 112, 112]        [16, 16, 112, 112]        False\n",
       "│    └─Sequential (2)                                        [16, 16, 112, 112]        [16, 24, 56, 56]          False\n",
       "│    │    └─MBConv (0)                                       [16, 16, 112, 112]        [16, 24, 56, 56]          False\n",
       "│    │    └─MBConv (1)                                       [16, 24, 56, 56]          [16, 24, 56, 56]          False\n",
       "│    └─Sequential (3)                                        [16, 24, 56, 56]          [16, 40, 28, 28]          False\n",
       "│    │    └─MBConv (0)                                       [16, 24, 56, 56]          [16, 40, 28, 28]          False\n",
       "│    │    └─MBConv (1)                                       [16, 40, 28, 28]          [16, 40, 28, 28]          False\n",
       "│    └─Sequential (4)                                        [16, 40, 28, 28]          [16, 80, 14, 14]          False\n",
       "│    │    └─MBConv (0)                                       [16, 40, 28, 28]          [16, 80, 14, 14]          False\n",
       "│    │    └─MBConv (1)                                       [16, 80, 14, 14]          [16, 80, 14, 14]          False\n",
       "│    │    └─MBConv (2)                                       [16, 80, 14, 14]          [16, 80, 14, 14]          False\n",
       "│    └─Sequential (5)                                        [16, 80, 14, 14]          [16, 112, 14, 14]         False\n",
       "│    │    └─MBConv (0)                                       [16, 80, 14, 14]          [16, 112, 14, 14]         False\n",
       "│    │    └─MBConv (1)                                       [16, 112, 14, 14]         [16, 112, 14, 14]         False\n",
       "│    │    └─MBConv (2)                                       [16, 112, 14, 14]         [16, 112, 14, 14]         False\n",
       "│    └─Sequential (6)                                        [16, 112, 14, 14]         [16, 192, 7, 7]           False\n",
       "│    │    └─MBConv (0)                                       [16, 112, 14, 14]         [16, 192, 7, 7]           False\n",
       "│    │    └─MBConv (1)                                       [16, 192, 7, 7]           [16, 192, 7, 7]           False\n",
       "│    │    └─MBConv (2)                                       [16, 192, 7, 7]           [16, 192, 7, 7]           False\n",
       "│    │    └─MBConv (3)                                       [16, 192, 7, 7]           [16, 192, 7, 7]           False\n",
       "│    └─Sequential (7)                                        [16, 192, 7, 7]           [16, 320, 7, 7]           False\n",
       "│    │    └─MBConv (0)                                       [16, 192, 7, 7]           [16, 320, 7, 7]           False\n",
       "│    └─Conv2dNormActivation (8)                              [16, 320, 7, 7]           [16, 1280, 7, 7]          True\n",
       "│    │    └─Conv2d (0)                                       [16, 320, 7, 7]           [16, 1280, 7, 7]          True\n",
       "│    │    └─BatchNorm2d (1)                                  [16, 1280, 7, 7]          [16, 1280, 7, 7]          True\n",
       "│    │    └─SiLU (2)                                         [16, 1280, 7, 7]          [16, 1280, 7, 7]          --\n",
       "├─AdaptiveAvgPool2d (block_2)                                [16, 1280, 7, 7]          [16, 1280, 1, 1]          --\n",
       "├─Flatten (flatten)                                          [16, 1280, 1, 1]          [16, 1280]                --\n",
       "├─Sequential (block_3)                                       [16, 1280]                [16, 3]                   True\n",
       "│    └─Dropout (0)                                           [16, 1280]                [16, 1280]                --\n",
       "│    └─Linear (1)                                            [16, 1280]                [16, 3]                   True\n",
       "=======================================================================================================================================\n",
       "Total params: 4,011,391\n",
       "Trainable params: 416,003\n",
       "Non-trainable params: 3,595,388\n",
       "Total mult-adds (G): 6.15\n",
       "=======================================================================================================================================\n",
       "Input size (MB): 9.63\n",
       "Forward/backward pass size (MB): 1726.05\n",
       "Params size (MB): 16.05\n",
       "Estimated Total Size (MB): 1751.73\n",
       "======================================================================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "transfer.unfreeze(num_trainable=3)\n",
    "summary(transfer, [16, 3, 224, 224], col_names=['input_size','output_size','trainable'], row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "819346c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Transfered_Model' object has no attribute 'optimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, param_group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtransfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241m.\u001b[39mparam_groups):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroup \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: lr = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, num_params = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(param_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Python\\envs\\DL_ENV\\lib\\site-packages\\torch\\nn\\modules\\module.py:1964\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1962\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1963\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1964\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1965\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1966\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Transfered_Model' object has no attribute 'optimizer'"
     ]
    }
   ],
   "source": [
    "for i, param_group in enumerate(transfer.optimizer.param_groups):\n",
    "    print(f\"Group {i}: lr = {param_group['lr']}, num_params = {len(param_group['params'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4a82f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in model.features.parameters():\n",
    "    params.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7cfb6d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=======================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape               Output Shape              Trainable\n",
       "=======================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]         [32, 1000]                Partial\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]         [32, 1280, 7, 7]          False\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]         [32, 32, 112, 112]        False\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]         [32, 32, 112, 112]        False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]        [32, 32, 112, 112]        False\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]        [32, 32, 112, 112]        --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]        [32, 16, 112, 112]        False\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]        [32, 16, 112, 112]        False\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]        [32, 24, 56, 56]          False\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]        [32, 24, 56, 56]          False\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]          [32, 24, 56, 56]          False\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]          [32, 40, 28, 28]          False\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]          [32, 40, 28, 28]          False\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]          [32, 40, 28, 28]          False\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28]          [32, 80, 14, 14]          False\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]          [32, 80, 14, 14]          False\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]          [32, 80, 14, 14]          False\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]          [32, 80, 14, 14]          False\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14]          [32, 112, 14, 14]         False\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]          [32, 112, 14, 14]         False\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]         [32, 112, 14, 14]         False\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]         [32, 112, 14, 14]         False\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14]         [32, 192, 7, 7]           False\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]         [32, 192, 7, 7]           False\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]           [32, 192, 7, 7]           False\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]           [32, 192, 7, 7]           False\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]           [32, 192, 7, 7]           False\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7]           [32, 320, 7, 7]           False\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]           [32, 320, 7, 7]           False\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]           [32, 1280, 7, 7]          False\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]           [32, 1280, 7, 7]          False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]          [32, 1280, 7, 7]          False\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]          [32, 1280, 7, 7]          --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]          [32, 1280, 1, 1]          --\n",
       "├─Sequential (classifier)                                    [32, 1280]                [32, 1000]                True\n",
       "│    └─Dropout (0)                                           [32, 1280]                [32, 1280]                --\n",
       "│    └─Linear (1)                                            [32, 1280]                [32, 1000]                True\n",
       "=======================================================================================================================================\n",
       "Total params: 5,288,548\n",
       "Trainable params: 1,281,000\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (G): 12.35\n",
       "=======================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.35\n",
       "Params size (MB): 21.15\n",
       "Estimated Total Size (MB): 3492.77\n",
       "======================================================================================================================================="
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, [32,3,224,224], col_names=['input_size', 'output_size', 'trainable'], row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef560b12",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m datamodule\u001b[38;5;241m.\u001b[39msetup()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# ví dụ:\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m img \u001b[38;5;241m=\u001b[39m unnormalize(X[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img)\n",
      "File \u001b[1;32md:\\Python\\envs\\DL_ENV\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 732\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    738\u001b[0m ):\n",
      "File \u001b[1;32md:\\Python\\envs\\DL_ENV\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1482\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1482\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1485\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\envs\\DL_ENV\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1444\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1440\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1441\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1443\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1444\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1445\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1446\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32md:\\Python\\envs\\DL_ENV\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1275\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1272\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1273\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1275\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1278\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\envs\\DL_ENV\\lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32md:\\Python\\envs\\DL_ENV\\lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\envs\\DL_ENV\\lib\\multiprocessing\\connection.py:330\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    328\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\Python\\envs\\DL_ENV\\lib\\multiprocessing\\connection.py:879\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    876\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    877\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 879\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32md:\\Python\\envs\\DL_ENV\\lib\\multiprocessing\\connection.py:811\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    809\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 811\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "datamodule.setup()\n",
    "# ví dụ:\n",
    "X, y = next(iter(datamodule.test_dataloader()))\n",
    "img = unnormalize(X[0]).permute(1,2,0)\n",
    "plt.imshow(img)\n",
    "plt.title(y[0].item())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc98b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 3, 224, 224])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316310c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = efficient_b0.Transfered_Model.load_from_checkpoint(checkpoint_path=r'tb_log\\lightning_logs\\version_0\\checkpoints\\epoch=9-step=50.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab4d8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_checker.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_checker.py\n",
    "'''\n",
    "Hàm vẽ hình và so sánh dự đoán giữa pred và truth\n",
    "\n",
    "Tham số:\n",
    "bs: batch_size\n",
    "\n",
    "Trả về:\n",
    "3 hình ảnh và cặp truth, pred\n",
    "'''\n",
    "from backbones import efficient_b0 # đổi class này nếu dùng backbone khác\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from dataloader import dataprocess\n",
    "import torch\n",
    "from pathlib import Path\n",
    "def pred_and_plot(base_model, bs = 32, checkpoint_path : str):\n",
    "    def unnormalize(img):\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "        std = torch.tensor([0.229, 0.224, 0.225])\n",
    "        img = img * std[:, None, None] + mean[:, None, None]\n",
    "        return img.clamp(0, 1)\n",
    "        \n",
    "    device = torch.device('cuda:0')\n",
    "\n",
    "    datamodule = dataprocess.DataModule(bs)\n",
    "    datamodule.setup(stage = 'test')\n",
    "    test_loader = datamodule.test_dataloader()\n",
    "\n",
    "    random_idx = np.random.randint(0,len(test_loader.dataset),3)\n",
    "    best_model = efficient_b0.Transfered_Model.load_from_checkpoint(checkpoint_path=checkpoint_path).to(device)\n",
    "    best_model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for id in random_idx:\n",
    "            plt.figure(figsize=(10,4))\n",
    "            plt.imshow(unnormalize(test_loader.dataset[id][0]).permute(1,2,0))\n",
    "            plt.axis(False)\n",
    "            logits = best_model(test_loader.dataset[id][0].unsqueeze(0).to(device))\n",
    "            pred = logits.argmax(1)\n",
    "            plt.title([test_loader.dataset[id][1].item(), pred.item()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f72ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from dataloader import dataprocess # Giả sử import đúng\n",
    "from backbones import efficient_b0 # Giả sử import đúng\n",
    "import torch\n",
    "\n",
    "def pred_and_plot(bs=32, num_samples=3): # Thêm num_samples\n",
    "    '''\n",
    "    Hàm vẽ hình và so sánh dự đoán giữa pred và truth\n",
    "\n",
    "    Tham số:\n",
    "    bs: batch_size dùng cho DataLoader\n",
    "    num_samples: Số lượng ảnh muốn vẽ\n",
    "\n",
    "    Trả về:\n",
    "    num_samples hình ảnh và cặp truth, pred\n",
    "    '''\n",
    "    # --- 1. Xác định device ---\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # --- 2. Hàm unnormalize ---\n",
    "    def unnormalize(img):\n",
    "        # Giả sử đây là mean/std chuẩn của ImageNet hoặc khớp với lúc train\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).to(device) # Chuyển mean/std sang device\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
    "        img = img * std[:, None, None] + mean[:, None, None]\n",
    "        return img.clamp(0, 1)\n",
    "\n",
    "    # --- 3. Chuẩn bị DataLoader ---\n",
    "    datamodule = dataprocess.DataModule(bs)\n",
    "    datamodule.setup(stage='test') # Chỉ setup stage test\n",
    "    test_loader = datamodule.test_dataloader()\n",
    "    class_names = datamodule.get_class_names() # Lấy tên lớp\n",
    "\n",
    "    # --- 4. Load Model ---\n",
    "    # Nên truyền checkpoint_path như một tham số\n",
    "    checkpoint_path = r'tb_log\\lightning_logs\\version_0\\checkpoints\\epoch=9-step=50.ckpt'\n",
    "    try:\n",
    "        best_model = efficient_b0.Transfered_Model.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
    "        best_model.to(device) # Chuyển model sang device\n",
    "        best_model.eval()\n",
    "        print(f\"Model loaded successfully from {checkpoint_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Checkpoint file not found at {checkpoint_path}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 5. Lấy mẫu ngẫu nhiên và dự đoán ---\n",
    "    images_to_plot = []\n",
    "    labels_to_plot = []\n",
    "    preds_to_plot = []\n",
    "\n",
    "    # Lấy ngẫu nhiên num_samples từ test_loader mà không cần tải hết\n",
    "    indices = random.sample(range(len(test_loader.dataset)), num_samples)\n",
    "    for idx in indices:\n",
    "        img, label = test_loader.dataset[idx] # Lấy trực tiếp từ dataset\n",
    "        images_to_plot.append(img)\n",
    "        labels_to_plot.append(label)\n",
    "\n",
    "        # Dự đoán cho từng ảnh (thêm chiều batch)\n",
    "        img_batch = img.unsqueeze(0).to(device) # Thêm chiều batch và chuyển sang device\n",
    "        with torch.inference_mode():\n",
    "            logits = best_model(img_batch)\n",
    "            pred_label = logits.argmax(1).squeeze().item() # Lấy index dự đoán\n",
    "            preds_to_plot.append(pred_label)\n",
    "\n",
    "    # --- 6. Vẽ hình ---\n",
    "    plt.figure(figsize=(10, num_samples * 3.5)) # Điều chỉnh figsize\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(num_samples, 1, i+1)\n",
    "        # Chuyển ảnh về CPU để unnormalize và plot nếu cần\n",
    "        img_display = unnormalize(images_to_plot[i].to(device)).cpu()\n",
    "        plt.imshow(img_display.permute(1, 2, 0))\n",
    "        plt.axis(False)\n",
    "        true_label_name = class_names[labels_to_plot[i]]\n",
    "        pred_label_name = class_names[preds_to_plot[i]]\n",
    "        title_color = 'g' if true_label_name == pred_label_name else 'r'\n",
    "        plt.title(f\"Truth: {true_label_name} | Pred: {pred_label_name}\", color=title_color)\n",
    "    plt.tight_layout() # Giúp các subplot không bị chồng chéo\n",
    "    plt.show()\n",
    "\n",
    "# Gọi hàm để chạy\n",
    "# pred_and_plot(bs=32, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48995fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import F1Score,ConfusionMatrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "def show_confusion_matrix(model, datamodule):\n",
    "    device = torch.device('cuda:0')\n",
    "    datamodule.setup(stage = 'test')\n",
    "    test_loader = datamodule.test_dataloader()\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X,_ in test_loader:\n",
    "            logits = model(X.to(device))\n",
    "            predictions.append(logits.argmax(1).to('cpu'))\n",
    "        predictions = torch.concat(predictions)\n",
    "    confmat = ConfusionMatrix(task = 'multiclass', num_classes=len(datamodule.get_class_names()))\n",
    "    confmat_data = confmat(predictions, torch.Tensor(test_loader.dataset.targets))\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=confmat_data.numpy(),\n",
    "                                    class_names=datamodule.get_class_names(),\n",
    "                                    figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a01f05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_confusion_matrix(best_model, datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
